{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizagem de Máquina I\n",
    "\n",
    "## Hugo Tremonte de Carvalho\n",
    "\n",
    "#### hugo@dme.ufrj.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo dessa atividade é resolver um problema de regressão linear em uma base de dados real. Mais especificamente, o objetivo é trabalhar sobre [esta base](https://archive.ics.uci.edu/dataset/464/superconductivty+data), do repositório da Universidade da Califórnia, que relaciona a temperatura crítica de supercondutores com estatísticas-resumo de certas propriedades físico-químicas desses materiais. Para mais detalhes, veja [esse artigo](https://arxiv.org/pdf/1803.10260).\n",
    "\n",
    "*Obs.: A temperatura crítica de um supercondutor é a temperatura abaixo da qual o material perde totalmente sua resistência elétrica e se torna um supercondutor, ou seja, passa a conduzir corrente elétrica com resistência nula e a expelir campos magnéticos de seu interior.*\n",
    "\n",
    "Esse conjunto de dados consiste de $n = 21.263$ observações e um total de $p = 81$ atributos. Note que ainda não estamos em um cenário tão desfavorável de modo que tenhamos $p \\approx n$. A temperatura crítica do supercondutor, representada na coluna de nome `critical_temp`, está medida em Kelvin (K = °C - 273,15), e é tal quantidade que deve ser prevista por você com base nos $p = 81$ atributos.\n",
    "\n",
    "Portanto, a nossa missão para esta atividade é utilizar as técnicas de regressão que estudamos até o momento para encontrar uma boa forma de prever a variável resposta a partir dos atributos. Para isso, siga o roteiro abaixo:\n",
    "* Faça uma análise exploratória para entneder como os seus atributos se comportam, se há multicolinearidade, se algum deles é bastante correlacionado com a resposta, etc.\n",
    "* Note que alguns atributos têm uma ordem de grandeza bem discrepante, o que pode ser numericamente problemático. Iremos tratar disso na terceira parte dessa aula.\n",
    "* Separe o seu conjunto de dados em treinamento e teste\n",
    "* Faça ajustes dos modelos de regressão que aprendemos, implementando alguma busca por validação cruzada no conjunto de treinamento para encontrar hiperparâmetros ótimos, quando for pertinente.\n",
    "* Avalie o desempenho do seu modelo no conjunto de teste, e reporte os seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados e análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/HugoCarvalhoUFRJ/ap-maq/refs/heads/main/materiais-didaticos/superconductivity.csv\", sep = ',')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se há dados faltantes\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se há linhas duplicadas\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas duplicadas\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html\n",
    "# ATENÇÃO: ESTAMOS SOBRESCREVENDO A VARIÁVEI df\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vendo se está tudo em ordem\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlação LINEAR entre os atributos e a resposta?\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "mask = np.triu(np.ones_like(df.corr(), dtype=bool))\n",
    "sns.heatmap(df.corr(method = 'pearson'), annot=False, mask=mask, vmin=-1, vmax=1, cmap = \"vlag\")\n",
    "plt.title('Correlações LINEARES entre os atributos e a resposta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlação MAIS GERAL entre os atributos?\n",
    "# https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "mask = np.triu(np.ones_like(df.corr(), dtype=bool))\n",
    "sns.heatmap(df.corr(method = 'spearman'), annot=False, mask=mask, vmin=-1, vmax=1, cmap = \"vlag\")\n",
    "plt.title('Correlações MAIS GERAIS entre os atributos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando de outra forma, focando na variável resposta\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.stem(df.corr(method = 'pearson')['critical_temp'], label = 'Pearson', markerfmt = '.b')\n",
    "plt.stem(df.corr(method = 'spearman')['critical_temp'], label = 'Spearman', markerfmt = '.r')\n",
    "plt.xticks(range(len(list(df.columns))), list(df.columns), rotation = 'vertical')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de dispersão contra a variável resposta\n",
    "\n",
    "n_cols = 5\n",
    "n_features = df.shape[1]\n",
    "n_rows = -(-n_features // n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(df.columns):\n",
    "    axes[i].scatter(df[col], df['critical_temp'], alpha=0.5, s=5)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(\"critical_temp\")\n",
    "\n",
    "# Se sobrar espaço na grade, remover eixos extras\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valide o desempenho de modelos de regressão linear e KNN. Mais especificamente, use o conjunto de teste para treinar modelos de regressão linear com e sem penalização (encontrando hiperparâmetros ótimos por validação cruzada) e um modelo de KNN (também encontrando hiperparâmetros ótimos por validação cruzada), e meça o seu desempenho no conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valide o desempenho de modelos de regressão baseados em árvores e o bagging para a regressão linear. Mais especificamente, use o conjunto de teste para treinar modelos de regressão baseados em árvores e o bagging para a regressão linear (encontrando hiperparâmetros ótimos por validação cruzada) e meça o seu desempenho no conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refaça as partes 1 e 2, utilizando uma `Pipeline` para acoplar um `StandardScaler` a cada um dos modelos de regressão empregados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
